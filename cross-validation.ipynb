{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30702,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport xgboost as xb\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import train_test_split, KFold, StratifiedKFold, cross_val_score\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:20:04.160882Z","iopub.execute_input":"2024-04-19T09:20:04.161360Z","iopub.status.idle":"2024-04-19T09:20:07.164767Z","shell.execute_reply.started":"2024-04-19T09:20:04.161321Z","shell.execute_reply":"2024-04-19T09:20:07.163446Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Gettting Synthetic data & splitting","metadata":{}},{"cell_type":"code","source":"make_classification","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:21:00.209512Z","iopub.execute_input":"2024-04-19T09:21:00.211031Z","iopub.status.idle":"2024-04-19T09:21:00.220940Z","shell.execute_reply.started":"2024-04-19T09:21:00.210969Z","shell.execute_reply":"2024-04-19T09:21:00.219660Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"<function sklearn.datasets._samples_generator.make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)>"},"metadata":{}}]},{"cell_type":"code","source":"X, y = make_classification(n_samples = 1000, n_features=20,\n                          n_informative = 2,n_redundant=10,random_state = 42\n                          )\n","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:23:02.172284Z","iopub.execute_input":"2024-04-19T09:23:02.172874Z","iopub.status.idle":"2024-04-19T09:23:02.190546Z","shell.execute_reply.started":"2024-04-19T09:23:02.172827Z","shell.execute_reply":"2024-04-19T09:23:02.189152Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:23:34.644967Z","iopub.execute_input":"2024-04-19T09:23:34.645436Z","iopub.status.idle":"2024-04-19T09:23:34.653050Z","shell.execute_reply.started":"2024-04-19T09:23:34.645398Z","shell.execute_reply":"2024-04-19T09:23:34.652113Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array([[-0.49693203, -0.33912228,  0.22914552, ..., -1.17927302,\n         0.45780561,  0.35600629],\n       [ 0.01249932,  1.00744397,  0.14009566, ..., -1.76385344,\n         0.93791554,  0.45936344],\n       [-0.72021202, -1.24448645, -0.47229097, ...,  0.41394755,\n        -0.5387903 , -0.26636053],\n       ...,\n       [ 1.01027459, -0.13092581,  1.18030384, ..., -1.98959095,\n        -0.80579965,  0.88702644],\n       [-1.20775939, -0.3807634 ,  0.12906749, ..., -0.77725344,\n         0.59910333,  0.22671772],\n       [ 1.14356604, -0.42459817, -0.31394763, ...,  1.24769039,\n        -0.30704834, -0.40246308]])"},"metadata":{}}]},{"cell_type":"code","source":"y","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:23:16.507179Z","iopub.execute_input":"2024-04-19T09:23:16.508258Z","iopub.status.idle":"2024-04-19T09:23:16.522225Z","shell.execute_reply.started":"2024-04-19T09:23:16.508202Z","shell.execute_reply":"2024-04-19T09:23:16.520641Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n       1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n       1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n       0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n       1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n       0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n       0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n       0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n       0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n       1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n       0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1,\n       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n       1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0,\n       0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n       0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n       0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n       0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n       0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n       1, 1, 1, 0, 0, 1, 0, 1, 0, 1])"},"metadata":{}}]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.30, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:24:55.788663Z","iopub.execute_input":"2024-04-19T09:24:55.789231Z","iopub.status.idle":"2024-04-19T09:24:55.798128Z","shell.execute_reply.started":"2024-04-19T09:24:55.789192Z","shell.execute_reply":"2024-04-19T09:24:55.796852Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## XGBoost Classifier","metadata":{}},{"cell_type":"code","source":"clf = xb.XGBClassifier(use_label_encoder=False, eval_matric ='logloss')\nclf.fit(X_train, y_train)  # train & test data seperated","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:34:45.706486Z","iopub.execute_input":"2024-04-19T09:34:45.707048Z","iopub.status.idle":"2024-04-19T09:34:45.874665Z","shell.execute_reply.started":"2024-04-19T09:34:45.707013Z","shell.execute_reply":"2024-04-19T09:34:45.873555Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_matric='logloss', eval_metric=None,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n              n_jobs=None, num_parallel_tree=None, ...)","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_matric=&#x27;logloss&#x27;, eval_metric=None,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n              n_jobs=None, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_matric=&#x27;logloss&#x27;, eval_metric=None,\n              feature_types=None, gamma=None, grow_policy=None,\n              importance_type=None, interaction_constraints=None,\n              learning_rate=None, max_bin=None, max_cat_threshold=None,\n              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n              max_leaves=None, min_child_weight=None, missing=nan,\n              monotone_constraints=None, multi_strategy=None, n_estimators=None,\n              n_jobs=None, num_parallel_tree=None, ...)</pre></div></div></div></div></div>"},"metadata":{}}]},{"cell_type":"code","source":"clf.score(X_test, y_test) # evaluting unseen / testing data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:12:04.909786Z","iopub.execute_input":"2024-04-19T11:12:04.910333Z","iopub.status.idle":"2024-04-19T11:12:04.933230Z","shell.execute_reply.started":"2024-04-19T11:12:04.910298Z","shell.execute_reply":"2024-04-19T11:12:04.932008Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"0.9133333333333333"},"metadata":{}}]},{"cell_type":"markdown","source":"## K-Fold Cross Validation","metadata":{}},{"cell_type":"code","source":"kf = KFold(n_splits=5, random_state=42, shuffle=True) \nkf_scores = cross_val_score(clf, X,y, cv=kf) # work on full data(X,y),not on train & test. 5 splits that mean each fold contain 20% of data","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:18:46.951753Z","iopub.execute_input":"2024-04-19T11:18:46.952293Z","iopub.status.idle":"2024-04-19T11:18:47.536227Z","shell.execute_reply.started":"2024-04-19T11:18:46.952258Z","shell.execute_reply":"2024-04-19T11:18:47.535044Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"kf_scores","metadata":{"execution":{"iopub.status.busy":"2024-04-19T09:52:52.797157Z","iopub.execute_input":"2024-04-19T09:52:52.797793Z","iopub.status.idle":"2024-04-19T09:52:52.806969Z","shell.execute_reply.started":"2024-04-19T09:52:52.797744Z","shell.execute_reply":"2024-04-19T09:52:52.805652Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"array([0.915, 0.925, 0.91 , 0.9  , 0.885])"},"metadata":{}}]},{"cell_type":"code","source":"kf_scores.mean()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:19:22.221379Z","iopub.execute_input":"2024-04-19T11:19:22.222661Z","iopub.status.idle":"2024-04-19T11:19:22.231928Z","shell.execute_reply.started":"2024-04-19T11:19:22.222603Z","shell.execute_reply":"2024-04-19T11:19:22.230535Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"0.907"},"metadata":{}}]},{"cell_type":"markdown","source":"## Stratefied K-Fold Cross- validation","metadata":{}},{"cell_type":"markdown","source":"- In each data distribution will be same/ equal","metadata":{}},{"cell_type":"code","source":"skf = KFold(n_splits=5, random_state=42, shuffle=True)\nskf_scores = cross_val_score(clf,X, y, cv=skf)","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:27:49.917009Z","iopub.execute_input":"2024-04-19T10:27:49.917525Z","iopub.status.idle":"2024-04-19T10:27:50.533159Z","shell.execute_reply.started":"2024-04-19T10:27:49.917492Z","shell.execute_reply":"2024-04-19T10:27:50.532072Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"skf_scores","metadata":{"execution":{"iopub.status.busy":"2024-04-19T10:53:19.252290Z","iopub.execute_input":"2024-04-19T10:53:19.253428Z","iopub.status.idle":"2024-04-19T10:53:19.261045Z","shell.execute_reply.started":"2024-04-19T10:53:19.253382Z","shell.execute_reply":"2024-04-19T10:53:19.259863Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"array([0.915, 0.925, 0.91 , 0.9  , 0.885])"},"metadata":{}}]},{"cell_type":"code","source":"skf_scores.mean()","metadata":{"execution":{"iopub.status.busy":"2024-04-19T11:19:36.198186Z","iopub.execute_input":"2024-04-19T11:19:36.198657Z","iopub.status.idle":"2024-04-19T11:19:36.207361Z","shell.execute_reply.started":"2024-04-19T11:19:36.198623Z","shell.execute_reply":"2024-04-19T11:19:36.206201Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"0.907"},"metadata":{}}]},{"cell_type":"markdown","source":"### Notes","metadata":{}},{"cell_type":"markdown","source":"#### Why XGBoost Considered as Ensemble Machine Learning algorithm ?","metadata":{}},{"cell_type":"markdown","source":"XGBoost, short for eXtreme Gradient Boosting, is indeed an ensemble machine learning algorithm. Let me explain why:\n\n<b> 1. Ensemble Learning:</b>\nEnsemble learning combines the predictions of multiple weak models (also known as base models or learners) to create a stronger model.\nThe idea is that by combining the outputs of several individual models, we can improve overall prediction accuracy and robustness.\n\n2. Gradient Boosting:\nXGBoost is based on the gradient boosting framework.\nGradient boosting is an iterative technique that builds a strong model by sequentially adding weak models to correct the errors made by the previous ones.\nIt minimizes a loss function by adjusting the weights of individual models during training\n\n3. Decision Trees:\nXGBoost uses a decision tree-based approach.\nEach tree in XGBoost is trained on a subset of the data and a random selection of features.\nDecision trees are simple models that make predictions based on a series of binary decisions (tests on attribute values).\n\n4. Combining Weak Models:\nXGBoost combines multiple decision trees (weak models) to create a more powerful ensemble.\nEach tree contributes to the final prediction, and their outputs are combined using a weighted sum.\n\n5. Efficiency and Scalability:\nXGBoost is designed for efficient and scalable training of machine learning models.\nIt handles large datasets effectively and achieves state-of-the-art performance.\nBuilt-in support for parallel processing allows training on large datasets within a reasonable time.\n\n6. Handling Missing Values:\nXGBoost efficiently handles missing values without requiring extensive pre-processing.\nThis makes it suitable for real-world data with incomplete information.\n\n7. Customizability:\nXGBoost is highly customizable.\nYou can fine-tune various model parameters to optimize performance for specific tasks.\nIn summary, XGBoost’s ability to combine weak models, handle missing values, and achieve high performance has made it a popular choice for various machine learning tasks, including classification, regression, and recommendation systems","metadata":{}},{"cell_type":"markdown","source":"- Make_classification : its a module for generating dataset, or make_regression\n- cross_val_score: for evaluating scores\n\n","metadata":{}},{"cell_type":"markdown","source":"## Difference between Kfold & Stratified Kfolds","metadata":{}},{"cell_type":"markdown","source":"Let’s explore the main differences between KFold and StratifiedKFold:\n\nKFold:\nKFold is a cross-validator that divides the dataset into k folds.\nIt randomly splits the data into training and test sets, ensuring that each fold contains an equal number of samples.\nThe class distribution is not considered during the split.\nIt is commonly used for regression tasks or when the class distribution is balanced.\n\nStratifiedKFold:\nStratifiedKFold is also a cross-validator, but it returns stratified folds.\nIt ensures that each fold has the same proportion of observations for each class as the original dataset.\nStratifiedKFold is particularly useful for classification tasks with imbalanced class distributions.\nIt helps maintain the class balance in both training and test sets.\n\nExample:\nSuppose we have a dataset with 16 data points: 12 belong to class A, and 4 belong to class B (imbalanced).\nIf we use StratifiedKFold with k = 4, each fold will have 9 data points from class A and 3 data points from class B in the training set. The test set will have 3 data points from class A and 1 data point from class B.\nIn contrast, KFold would not consider class proportions and might create imbalanced splits.\n\nWhen to Use:\nKFold: Use KFold when dealing with balanced datasets or regression tasks.\nStratifiedKFold: Prefer StratifiedKFold when handling classification tasks with imbalanced class distributions.\nIn summary, StratifiedKFold is an improved version of KFold that preserves class proportions, making it more suitable for imbalanced datasets","metadata":{}}]}