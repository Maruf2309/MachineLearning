{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bde54f7",
   "metadata": {},
   "source": [
    "# KFold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5e3d97",
   "metadata": {},
   "source": [
    "#### Importing the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc8b5986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd04877",
   "metadata": {},
   "source": [
    "##### Importing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4953657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad11b99",
   "metadata": {},
   "source": [
    "##### Data Collection & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1aef868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"D:\\ai_ds-General\\dataset\\heart_v1.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66291f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb8d8223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Missing Values (whole data)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f257ac14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "1    165\n",
       "0    138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of Target Variable (Checking balance or imbalance), 1: Defective Heart, 2:Healthy Heart\n",
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb349d0e",
   "metadata": {},
   "source": [
    "### Splitting the features & targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe65f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['target'], axis=1)\n",
    "y = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6487166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3982c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb884db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13) (242, 13) (61, 13) (242,) (61,)\n"
     ]
    }
   ],
   "source": [
    "# initialize train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=3)\n",
    "\n",
    "# check shape\n",
    "print(X.shape, X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a04a5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986798679867987"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "242/303"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376b34bf",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2e136",
   "metadata": {},
   "source": [
    "#### Compare the performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6996156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of models\n",
    "models = [LogisticRegression(max_iter=1000), SVC(kernel='linear'), KNeighborsClassifier(), RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b91f6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare models based on train_test_split fun\n",
    "def compare_models_train_test():\n",
    "    \n",
    "    # training each model indiviaually\n",
    "    for model in models:\n",
    "        \n",
    "        # train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # evaluating the model\n",
    "        train_data_prediction = model.predict(X_test)\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy = accuracy_score(y_test, train_data_prediction)\n",
    "        \n",
    "        # Print results\n",
    "        print('Accuracy Score of the', model, ' = ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9af4312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of the LogisticRegression(max_iter=1000)  =  0.7704918032786885\n",
      "Accuracy Score of the SVC(kernel='linear')  =  0.7704918032786885\n",
      "Accuracy Score of the KNeighborsClassifier()  =  0.6557377049180327\n",
      "Accuracy Score of the RandomForestClassifier()  =  0.7868852459016393\n"
     ]
    }
   ],
   "source": [
    "# calling function\n",
    "compare_models_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06447a97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa30a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991294f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbdea2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5843c74f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeee932f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd7e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85acf425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb443e0e",
   "metadata": {},
   "source": [
    "<center> <h2> Notes </h2> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc45ff7",
   "metadata": {},
   "source": [
    "## 1.0 Imbance & Balance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16b647",
   "metadata": {},
   "source": [
    "A balanced data set is one where the classes are approximately equally represented. An imbalanced data set is one where there is a significant difference between the number of instances of each class1.\n",
    "\n",
    "In your case, the target variable has two classes: 1 and 0. The class 1 has 165 instances, while the class 0 has 138 instances. The difference between the two classes is not very large, so this data set can be considered balanced.\n",
    "\n",
    "However, if the difference between the classes was much larger, such as 165 vs 15, then the data set would be imbalanced. This could cause problems for some machine learning algorithms, as they might learn to favor the majority class and ignore the minority class. In such cases, you might need to use some techniques to balance the data set, such as over-sampling, under-sampling, or synthetic data generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17a131",
   "metadata": {},
   "source": [
    "#### Q1. What is the ideal ratio for considering balance vs imbalance data ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c2c65a",
   "metadata": {},
   "source": [
    "There is no definitive answer to what constitutes a balanced or imbalanced data set, as it may depend on the context, the problem, and the algorithm you are using. However, some general guidelines are:\n",
    "\n",
    "A balanced data set is one where the classes are approximately equally represented. For example, a 50:50 or 60:40 split between two classes would be considered balanced\n",
    "\n",
    "An imbalanced data set is one where there is a significant difference between the number of instances of each class. For example, a 10:90 or 1:99 split between two classes would be considered imbalanced\n",
    "\n",
    "The degree of imbalance can be mild, moderate, or extreme, depending on the proportion of the minority class. For example, a binary classification problem with a minority class of 20-40% of the data set would be mildly imbalanced, while one with a minority class of less than 1% of the data set would be extremely imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee449f",
   "metadata": {},
   "source": [
    "#### Q2. Explain Over Sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e1ce8",
   "metadata": {},
   "source": [
    "Over-sampling is a technique for dealing with imbalanced data sets, where the number of instances of one class is much lower than the other classes. Over-sampling involves randomly duplicating examples from the minority class, with or without replacement, and adding them to the training data set. This way, the class distribution becomes more balanced and the learning algorithm can better capture the characteristics of the minority class\n",
    "\n",
    "However, over-sampling also has some drawbacks, such as increasing the computational cost and the risk of overfitting. Overfitting occurs when the model learns the noise or specific patterns of the minority class that are not generalizable to new data. To avoid overfitting, some variations of over-sampling have been proposed, such as Synthetic Minority Oversampling Technique (SMOTE), which creates new synthetic examples from the minority class instead of simply replicating them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf55203",
   "metadata": {},
   "source": [
    "#### Q3. Explain Under Sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22a25e",
   "metadata": {},
   "source": [
    "Under-sampling is a technique for dealing with imbalanced data sets, where the number of instances of one class is much lower than the other classes. Under-sampling involves randomly removing examples from the majority class, with or without replacement, and reducing the size of the training data set. This way, the class distribution becomes more balanced and the learning algorithm can better capture the characteristics of the minority class\n",
    "\n",
    "However, under-sampling also has some drawbacks, such as losing potentially useful information and increasing the risk of underfitting. Underfitting occurs when the model fails to learn the general patterns of the data and performs poorly on new data. To avoid underfitting, some variations of under-sampling have been proposed, such as Tomek Links, Edited Nearest Neighbors, and One-Sided Selection, which remove only the noisy or borderline examples from the majority class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa53940",
   "metadata": {},
   "source": [
    "#### Q4. Explain Synthetic data concept for handing imbalance dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830a514",
   "metadata": {},
   "source": [
    "Synthetic data is a technique for handling imbalanced data sets, where the number of instances of one class is much lower than the other classes. Synthetic data involves creating new examples from the minority class that are not present in the original data set, but are similar enough to represent its characteristics. This way, the class distribution becomes more balanced and the learning algorithm can better capture the features of the minority class\n",
    "\n",
    "There are different methods for generating synthetic data, such as SMOTE (Synthetic Minority Oversampling Technique), MBS (Model-Based Synthetic Sampling), and SYNAuG (Synthetic Augmentation). These methods use different approaches, such as interpolation, modeling, or augmentation, to create new synthetic examples from the minority class\n",
    "\n",
    "Synthetic data can help overcome some of the drawbacks of traditional sampling techniques, such as data loss, data duplication, or overfitting. However, synthetic data also has some challenges, such as ensuring the quality, validity, and diversity of the generated data, and avoiding introducing unwanted biases or noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb25bbe1",
   "metadata": {},
   "source": [
    "## 2.0 Rules for Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42adfd",
   "metadata": {},
   "source": [
    "- Step 1: Import module 'from sklearn.model_selection import train_test_split'\n",
    "- Step 2: Seperate X & y first\t\n",
    "- Step 3: Initialize Train Test spit > pass (X, y, test_size, stratify = y (optional), random_stat)\n",
    "- Step 4: Check & verify shape(X, y) Train vs train, test vs test shape must be same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95c48b7",
   "metadata": {},
   "source": [
    "##### Q1 Explain the concept of 'Stratify=y' in Train Test Split, y (dependent variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24432cff",
   "metadata": {},
   "source": [
    "The stratify parameter in the train_test_split function is used to split the data in a stratified fashion, meaning that the proportion of classes in the original data is preserved in the train and test sets. For example, if you have a binary classification problem with 60% of the data belonging to class 0 and 40% to class 1, setting stratify=Y will ensure that the train and test sets have the same ratio of 0s and 1s. This can help to avoid bias and improve the generalization of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff2bde6",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eebd34a",
   "metadata": {},
   "source": [
    "#### Q6 what is meat by Kernel='linear' ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f6da7",
   "metadata": {},
   "source": [
    "The kernel parameter in the SVC function specifies the type of hyperplane used to separate the data. A hyperplane is a boundary that divides the data into different classes. A linear kernel means that the hyperplane is a straight line (or a plane in higher dimensions). A linear kernel is suitable for data that is linearly separable, meaning that a line can separate the data without errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f407f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
